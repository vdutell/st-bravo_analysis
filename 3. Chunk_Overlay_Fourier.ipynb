{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Spatiotemporal Power Spectrum of Movies\n",
    "\n",
    "After Video Frames have been temporally synced on a common timeframe with the eye trackers, we can extract video frames knowing they are temporally synced to the eye tracker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, stat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imp\n",
    "\n",
    "import utils.run_analysis as ana\n",
    "\n",
    "import stftoolkit as stf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "*** NOTE: REALLY NEED TO CHECK ON THE VALUES FOR HORIZONTAL AND VERTICAL FOV ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical PPD: 24.90, Horizontal PPD 25.80, taking average 25.35\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/data_repo/bravo'\n",
    "data_dir = os.path.join(base_dir, 'raw_data')\n",
    "output_dir = os.path.join(base_dir, 'analysis')\n",
    "\n",
    "fps = 200\n",
    "\n",
    "###DEFINITELY NEED TO CHECK ON THESE VALUES\n",
    "horizontal_fov_deg = 80\n",
    "vertical_fov_deg = 62\n",
    "\n",
    "img_dims=(1544,2064)\n",
    "save_batchsize = 200\n",
    "\n",
    "chunk_secs = 5\n",
    "chunk_pix = 128\n",
    "\n",
    "#num_chunks = 5\n",
    "\n",
    "cosine_window = True\n",
    "\n",
    "vertical_ppd = img_dims[0]/vertical_fov_deg\n",
    "horizontal_ppd = img_dims[1]/horizontal_fov_deg\n",
    "ppd = np.mean((vertical_ppd, horizontal_ppd))\n",
    "print(f'Vertical PPD: {vertical_ppd:.2f}, Horizontal PPD {horizontal_ppd:.2f}, taking average {ppd:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Directories for Exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_subject = 'jf'\n",
    "example_trial = 'cell_phone_1'\n",
    "example_camera = 'cy'\n",
    "trial_directory = os.path.join(data_dir, example_subject, example_trial, 'pre')\n",
    "camera_dir = os.path.join(trial_directory,'scene_camera')\n",
    "\n",
    "analysis_folder = os.path.join(output_dir, example_subject, example_trial,'')\n",
    "common_timeline_file = os.path.join(analysis_folder,'common_timeline.npy')\n",
    "\n",
    "#three trace conditions: true, none, temporal_match, spatial_match \n",
    "trace='none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Traces To Overlay\n",
    "\n",
    "*** For now, only doing control conditions with random box in scene window. Later, the no trace condition should be MATCHED to a true fixation point START. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = np.load(common_timeline_file)\n",
    "timeline_stamps = timeline[:0]\n",
    "timeline_ximea = timeline[:,1].astype(int)\n",
    "timeline_pupil = timeline[:,2].astype(int)\n",
    "timeline_task = timeline[:,3].astype(int)\n",
    "\n",
    "#only use timelines during task\n",
    "timeline_ximea = timeline_ximea[timeline_task==1]\n",
    "timeline_pupil = timeline_pupil[timeline_task==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a trace\n",
    "chunk_fs = int(chunk_secs*fps)\n",
    "if(trace == 'none'):\n",
    "    trace_xy_corner = np.tile([np.random.randint(0,img_dims[0]-chunk_pix), np.random.randint(0,img_dims[1])-chunk_pix],(chunk_fs,1)) #top left corner\n",
    "    trace_f_start = np.random.randint(0, len(timeline_pupil) - chunk_fs)\n",
    "    trace_f = np.arange(trace_f_start, trace_f_start+chunk_fs)\n",
    "\n",
    "    trace_ximea_fnum = timeline_ximea[trace_f]\n",
    "    trace_pupil_fnum = timeline_pupil[trace_f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Movie at Trace x, y, f position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_folder\n",
    "start = 200\n",
    "trace_ximea_fnum = range(start, chunk_secs*fps+start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to grab full size movie at trace time\n",
    "#pull the movie at these frame numbers\n",
    "#full_movie = np.zeros((len(trace_f),*img_dims,3))\n",
    "#for i, f in enumerate(trace_f):\n",
    "#    full_movie[i] = ana.ximea_get_frame(f, save_batchsize, example_camera, camera_dir, img_dims=(1544,2064), normalize=True)\n",
    "\n",
    "import imageio\n",
    "\n",
    "movie_chunk = np.zeros((len(trace_f), chunk_pix, chunk_pix, 3))\n",
    "\n",
    "for i, f in enumerate(trace_ximea_fnum):\n",
    "    frame = imageio.imread(os.path.join(analysis_folder,'pngs','cy',f'frame_{f}.png'))\n",
    "#   frame = ana.ximea_get_frame(timeline_ximea[i], save_batchsize, example_camera, camera_dir, img_dims=(1544,2064), normalize=True)\n",
    "    frame = frame/np.max(frame)\n",
    "        \n",
    "    movie_chunk[i] = frame[trace_xy_corner[i,0]:trace_xy_corner[i,0]+chunk_pix, \n",
    "                           trace_xy_corner[i,1]:trace_xy_corner[i,1]+chunk_pix]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(movie_chunk[0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(movie_chunk[np.shape(movie_chunk)[0]//2])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(movie_chunk[-1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Spatiotemporal Fourier Transform of this Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_3d, ps_2d, fqs_space, fqs_time = stf.st_ps(movie_chunk, cosine_window=False, rm_dc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stf.da_plot_power(ps_2d, fqs_time, fqs_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the Average of Many Chunks and create FT plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-2b7dc2f7a786>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-2b7dc2f7a786>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    drift_traces, sac_traces, control_traces, full_trace, trace_fps = rtr.readSegTraces(tracepath, crop=True, minlen_sec=nsecs_drift, resample=movfps)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#old code from fixational eye motion analysis.\n",
    "\n",
    "print(f'Reading & Segmented Trace...', end='') # debugging\n",
    "            drift_traces, sac_traces, control_traces, full_trace, trace_fps = rtr.readSegTraces(tracepath, crop=True, minlen_sec=nsecs_drift, resample=movfps)\n",
    "            print(f'Done...', end='') # debugging\n",
    "\n",
    "            # report what we'll do\n",
    "            total_per_movie = len(drift_traces)*trace_resamples\n",
    "            print(f'Sampling {len(drift_traces)} drift segs; {trace_resamples} resamples: {total_per_movie} total.')\n",
    "\n",
    "            # loop through drift traces, sac and control have same indices\n",
    "            for i in range(len(drift_traces)):\n",
    "\n",
    "                drift_trace = drift_traces[i]\n",
    "                sac_trace = control_traces[i]\n",
    "                raw_trace = np.zeros_like(drift_trace) #control condition - no eye motion\n",
    "\n",
    "                repeats = 0\n",
    "                #  repeat the computation multiple times per trace\n",
    "                while(repeats < trace_resamples):\n",
    "                    repeats +=1\n",
    "                    \n",
    "                    #start with an empty movie to make sure the movie was calculated.\n",
    "                    raw_overlayMov = []\n",
    "                    c = []\n",
    "                    trace_overlayMov = []\n",
    "                    drift_overlayMov = []\n",
    "                    \n",
    "                    # just try again if our random numbers resultd in an incomplete movie:\n",
    "                    # this is contingent on olm.OverlayMov returning 0 for an incomplete movie.\n",
    "                    incomplete_counter = 0\n",
    "                    #print(full_movie.shape, window_size)\n",
    "                    while((len(trace_overlayMov)==0 or len(drift_overlayMov)==0) or len(raw_overlayMov)==0 ):\n",
    "                        #print(len(trace_overlayMov),len(drift_overlayMov),len(raw_overlayMov))\n",
    "                        #print(full_movie.shape, full_movie.shape[0]-raw_trace.shape[1]*movfps/trace_fps)\n",
    "                        # get rand values for spatial and temporal offsets\n",
    "                        # temporal offset should be between 0 and the total movie length less the chunk length.\n",
    "                        t_starts = [np.random.randint(0, int(full_movie.shape[0]-raw_trace.shape[1]*movfps/trace_fps)),\n",
    "                                  np.random.randint(0, int(full_movie.shape[0]-sac_trace.shape[1]*movfps/trace_fps)),\n",
    "                                  np.random.randint(0, int(full_movie.shape[0]-drift_trace.shape[1]*movfps/trace_fps))]\n",
    "                        \n",
    "                        # spatial offset start should have a 1xwindow size border, and are calculated from (0,0).\n",
    "                        x_offset = full_movie.shape[1]//2-window_size[0]//2\n",
    "                        y_offset = full_movie.shape[2]//2-window_size[1]//2\n",
    "                        # calc random positions in this range\n",
    "                        x_starts = [np.random.randint(-x_offset, x_offset),\n",
    "                                    np.random.randint(-x_offset, x_offset),\n",
    "                                    np.random.randint(-x_offset, x_offset)]\n",
    "                        y_starts = [np.random.randint(-y_offset, y_offset),\n",
    "                                    np.random.randint(-y_offset, y_offset),\n",
    "                                    np.random.randint(-y_offset, y_offset)]\n",
    "\n",
    "                        raw_overlayMov = olm.overlayMov(full_movie, movfps, movie_ppd, raw_trace, trace_fps,\n",
    "                                                        window_size, (x_starts[0], y_starts[0]), t_starts[0])\n",
    "                        trace_overlayMov = olm.overlayMov(full_movie, movfps, movie_ppd, sac_trace, trace_fps,\n",
    "                                                        window_size, (x_starts[1], y_starts[1]), t_starts[1])\n",
    "                        drift_overlayMov = olm.overlayMov(full_movie, movfps, movie_ppd, drift_trace, trace_fps,\n",
    "                                                        window_size, (x_starts[2], y_starts[2]), t_starts[2])\n",
    "                        img_overlayMov = olm.overlayMov(img_movie, movfps, movie_ppd, drift_trace, trace_fps,\n",
    "                                                        window_size, (x_starts[2], y_starts[2]), t_starts[2])\n",
    "                        \n",
    "                        incomplete_counter+=1\n",
    "                        if(incomplete_counter % 1000==0):\n",
    "                            print(f'Ovelay Failures: {incomplete_counter}: Window of trace overlay is probably wrong.')\n",
    "                            \n",
    "                    print('*',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

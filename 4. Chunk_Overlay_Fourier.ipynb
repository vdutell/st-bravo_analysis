{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Spatiotemporal Power Spectrum of Movies\n",
    "\n",
    "After Video Frames have been temporally synced on a common timeframe with the eye trackers, we can extract video frames knowing they are temporally synced to the eye tracker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, stat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imp\n",
    "\n",
    "import utils.run_analysis as ana\n",
    "\n",
    "import stftoolkit as stf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "*** NOTE: REALLY NEED TO CHECK ON THE VALUES FOR HORIZONTAL AND VERTICAL FOV ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical PPD: 24.90, Horizontal PPD 25.80, taking average 25.35\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/data_repo/bravo'\n",
    "data_dir = os.path.join(base_dir, 'raw_data')\n",
    "output_dir = os.path.join(base_dir, 'analysis')\n",
    "\n",
    "fps = 200\n",
    "\n",
    "###DEFINITELY NEED TO CHECK ON THESE VALUES\n",
    "horizontal_fov_deg = 80\n",
    "vertical_fov_deg = 62\n",
    "\n",
    "img_dims=(1544,2064)\n",
    "save_batchsize = 200\n",
    "\n",
    "chunk_secs = 5\n",
    "chunk_pix = 256\n",
    "\n",
    "num_chunks = 500\n",
    "\n",
    "cosine_window = True\n",
    "\n",
    "vertical_ppd = img_dims[0]/vertical_fov_deg\n",
    "horizontal_ppd = img_dims[1]/horizontal_fov_deg\n",
    "ppd = np.mean((vertical_ppd, horizontal_ppd))\n",
    "print(f'Vertical PPD: {vertical_ppd:.2f}, Horizontal PPD {horizontal_ppd:.2f}, taking average {ppd:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Directories for Exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_subject = 'jf'\n",
    "example_trial = 'cell_phone_1'\n",
    "example_camera = 'cy'\n",
    "trial_directory = os.path.join(data_dir, example_subject, example_trial, 'pre')\n",
    "camera_dir = os.path.join(trial_directory,'scene_camera')\n",
    "\n",
    "analysis_folder = os.path.join(output_dir, example_subject, example_trial,'')\n",
    "common_timeline_file = os.path.join(analysis_folder,'common_timeline.npy')\n",
    "\n",
    "#three trace conditions: true, none, temporal_match, spatial_match \n",
    "trace='none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Traces To Overlay\n",
    "\n",
    "*** For now, only doing control conditions with random box in scene window. Later, the no trace condition should be MATCHED to a true fixation point START. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = np.load(common_timeline_file)\n",
    "timeline_stamps = timeline[:0]\n",
    "timeline_ximea = timeline[:,1].astype(int)\n",
    "timeline_pupil = timeline[:,2].astype(int)\n",
    "timeline_task = timeline[:,3].astype(int)\n",
    "\n",
    "#only use timelines during task\n",
    "timeline_ximea = timeline_ximea[timeline_task==1]\n",
    "timeline_pupil = timeline_pupil[timeline_task==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a trace\n",
    "chunk_fs = int(chunk_secs*fps)\n",
    "if(trace == 'none'):\n",
    "    trace_xy_corner = np.tile([np.random.randint(0,img_dims[0]-chunk_pix), np.random.randint(0,img_dims[1])-chunk_pix],(chunk_fs,1)) #top left corner\n",
    "    trace_f_start = np.random.randint(0, len(timeline_pupil) - chunk_fs)\n",
    "    trace_f = np.arange(trace_f_start, trace_f_start+chunk_fs)\n",
    "\n",
    "    trace_ximea_fnum = timeline_ximea[trace_f]\n",
    "    trace_pupil_fnum = timeline_pupil[trace_f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Movie at Trace x, y, f position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_folder\n",
    "start = 2000\n",
    "trace_ximea_fnum = range(start, chunk_secs*fps+start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to grab full size movie at trace time\n",
    "#pull the movie at these frame numbers\n",
    "#full_movie = np.zeros((len(trace_f),*img_dims,3))\n",
    "#for i, f in enumerate(trace_f):\n",
    "#    full_movie[i] = ana.ximea_get_frame(f, save_batchsize, example_camera, camera_dir, img_dims=(1544,2064), normalize=True)\n",
    "\n",
    "import imageio\n",
    "\n",
    "movie_chunk = np.zeros((len(trace_f), chunk_pix, chunk_pix, 3))\n",
    "\n",
    "for i, f in enumerate(trace_ximea_fnum):\n",
    "    frame = imageio.imread(os.path.join(analysis_folder,'pngs','cy',f'frame_{f}.png'))\n",
    "#   frame = ana.ximea_get_frame(timeline_ximea[i], save_batchsize, example_camera, camera_dir, img_dims=(1544,2064), normalize=True)\n",
    "    #frame = frame/np.max(frame)\n",
    "        \n",
    "    movie_chunk[i] = frame[trace_xy_corner[i,0]:trace_xy_corner[i,0]+chunk_pix, \n",
    "                           trace_xy_corner[i,1]:trace_xy_corner[i,1]+chunk_pix]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_chunk_norm = movie_chunk/np.max(movie_chunk,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(movie_chunk_norm[0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(movie_chunk_norm[np.shape(movie_chunk_norm)[0]//2])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(movie_chunk_norm[-1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Spatiotemporal Fourier Transform of this Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_3d, ps_2d, fqs_space, fqs_time = stf.st_ps(movie_chunk, ppd, fps, cosine_window=False, rm_dc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(stf)\n",
    "stf.da_plot_power(ps_2d.T, fqs_space, fqs_time, show_onef_line=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the Average of Many Chunks and create FT plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_fs = int(chunk_secs*fps)\n",
    "\n",
    "ps_3d_mean = np.zeros_like(ps_3d)\n",
    "ps_2d_mean = np.zeros_like(ps_2d)\n",
    "\n",
    "print(f'Taking mean of {num_chunks} chunks...')\n",
    "for i in range(num_chunks):\n",
    "    if(trace == 'none'):\n",
    "        trace_xy_corner = np.tile([np.random.randint(0,img_dims[0]-chunk_pix-1), \n",
    "                                   np.random.randint(0,img_dims[1]-chunk_pix-1)],\n",
    "                                  (chunk_fs,1)) #top left corner\n",
    "        trace_f_start = np.random.randint(0, len(timeline_pupil) - chunk_fs)\n",
    "        trace_f = np.arange(trace_f_start, trace_f_start+chunk_fs)\n",
    "\n",
    "        trace_ximea_fnum = timeline_ximea[trace_f]\n",
    "        trace_pupil_fnum = timeline_pupil[trace_f]\n",
    "        \n",
    "        movie_chunk = np.zeros((len(trace_f), chunk_pix, chunk_pix, 3))\n",
    "        #print(movie_chunk.shape)\n",
    "        #print(trace_xy_corner[i,0], trace_xy_corner[i,1] )\n",
    "\n",
    "        for i, f in enumerate(trace_ximea_fnum):\n",
    "            frame = imageio.imread(os.path.join(analysis_folder,'pngs','cy',f'frame_{f}.png'))\n",
    "        #   frame = ana.ximea_get_frame(timeline_ximea[i], save_batchsize, example_camera, camera_dir, img_dims=(1544,2064), normalize=True)\n",
    "            #frame = frame/np.max(frame)\n",
    "            movie_chunk[i] = frame[trace_xy_corner[i,0]:trace_xy_corner[i,0]+chunk_pix, \n",
    "                                   trace_xy_corner[i,1]:trace_xy_corner[i,1]+chunk_pix]\n",
    "            \n",
    "        ps_3d, ps_2d, fqs_space, fqs_space = stf.st_ps(movie_chunk, ppd, fps, cosine_window=False, rm_dc=True)\n",
    "        ps_3d_mean += ps_3d\n",
    "        ps_2d_mean += ps_2d\n",
    "    print('*',end='')\n",
    "\n",
    "ps_3d_mean = ps_3d_mean/num_chunks\n",
    "ps_2d_mean = ps_2d_mean/num_chunks\n",
    "\n",
    "np.save(f'./output/ps_3d_mean_{num_chunks}.npy', ps_3d_mean)\n",
    "np.save(f'./output/ps_2d_mean_{num_chunks}.npy', ps_2d_mean)\n",
    "np.save(f'./output/ps_fqs_space_{num_chunks}.npy', fqs_space)\n",
    "np.save(f'./output/ps_fqs_time_{num_chunks}.npy', fqs_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stf.da_plot_power(ps_2d_mean.T, fqs_space, fqs_time, show_onef_line=False, figname=f'mean_Power_{num_chunks}_chunks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Separability\n",
    "\n",
    "We need to determine how close this function is to a separable function. According to  Constantinou et al 2015, (https://arxiv.org/pdf/1509.07017.pdf) We can do this by determining how factorizable the covariance matrix is.\n",
    "\n",
    "Another reference is Simpson et al (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4203479/)\n",
    "\n",
    "A more common method is looking at the rank of the matrix using SVD\n",
    "\n",
    "The interesting relationship in the power spectrum (1/f law) is in log space. So take the log before running SVD. This also puts the values of the matrix to max 30 or so, which is more numerically stable for SVD (values before log are 10^15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_2d_small = np.log(ps_2d_mean)\n",
    "plt.hist(ps_2d_small.flatten(),bins=100)\n",
    "#ps_2d_small = ps_2d_small/np.max(ps_2d_small) # no need to do this in log space\n",
    "u,s,v = np.linalg.svd(ps_2d_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(u)\n",
    "plt.colorbar()\n",
    "plt.title('u')\n",
    "plt.show()\n",
    "plt.plot(u[0,:],label='first col')\n",
    "plt.plot(u[:,0],label='first row')\n",
    "plt.legend()\n",
    "plt.title('U cols/rows')\n",
    "plt.show()\n",
    "print(f'Sigma Values: {[l for l in s[:5]]}')\n",
    "plt.plot(s[:20])\n",
    "plt.title('Sigma - first 30')\n",
    "plt.show()\n",
    "plt.pcolormesh(v)\n",
    "plt.colorbar()\n",
    "plt.title('V')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to be in the realm of 'sort-of' separable. The first SV is large, and the second and beyond are much smaller. But they are definitely not zero either. Looking at the first column (spatial frequency), there is some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
